import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import datetime
import os
import gspread
import json
import numpy as np
from google.oauth2.service_account import Credentials
from openai import OpenAI
from sklearn.cluster import KMeans

# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆæ—©ã‚ã«ï¼‰
st.set_page_config(page_title="LRADãƒãƒ£ãƒƒãƒˆ ã‚¤ãƒ³ã‚µã‚¤ãƒˆåˆ†æ", layout="wide")
st.title("ğŸ“Š LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ ã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(api_key=st.secrets.OpenAIAPI.openai_api_key)

# è³ªå•ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆã‹ã‚‰Embeddingã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_embeddings(texts):
    embeddings = []
    batch_size = 20  # APIåˆ¶é™ã‚’è€ƒæ…®
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input=batch
        )
        batch_embeddings = [e.embedding for e in response.data]
        embeddings.extend(batch_embeddings)
    return np.array(embeddings)

# Timestampã‚„dateå‹ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã™ã‚‹é–¢æ•°ï¼ˆGoogle Sheetsä¿å­˜ç”¨ï¼‰
def convert_timestamps_to_str(df):
    for col in df.columns:
        if pd.api.types.is_datetime64_any_dtype(df[col]):
            df[col] = df[col].dt.strftime('%Y-%m-%d %H:%M:%S')
        else:
            if not df[col].empty and isinstance(df[col].iloc[0], datetime.date):
                df[col] = df[col].astype(str)
    return df

# Google Sheetsã«ä¿å­˜ã™ã‚‹é–¢æ•°
def save_insight_to_gsheet(data: pd.DataFrame, sheet_name: str):
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    raw_info = st.secrets["GoogleSheets"]["service_account_info"]
    if isinstance(raw_info, str):
        info = json.loads(raw_info)
    else:
        info = raw_info
    creds = Credentials.from_service_account_info(info, scopes=scope)
    gc = gspread.authorize(creds)
    sheet_key = st.secrets["GoogleSheets"]["sheet_key"]
    sh = gc.open_by_key(sheet_key)
    try:
        worksheet = sh.worksheet(sheet_name)
    except gspread.WorksheetNotFound:
        worksheet = sh.add_worksheet(title=sheet_name, rows="1000", cols="20")
    worksheet.clear()
    data_to_save = convert_timestamps_to_str(data.copy())
    worksheet.update([data_to_save.columns.values.tolist()] + data_to_save.values.tolist())

# ãƒ­ã‚°èª­ã¿è¾¼ã¿
LOG_FILE = "chat_logs.csv"
if not os.path.exists(LOG_FILE):
    st.warning("âš ï¸ ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ï¼ˆchat_logs.csvï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

df = pd.read_csv(LOG_FILE)

if df.empty:
    st.info("ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ãŒã¾ã ä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ•´å½¢
df["timestamp"] = pd.to_datetime(df["timestamp"])
df["date"] = df["timestamp"].dt.date
df["hour"] = df["timestamp"].dt.hour
df["month"] = df["timestamp"].dt.to_period("M").astype(str)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šæ—¥ä»˜çµã‚Šè¾¼ã¿
st.sidebar.header("ğŸ” çµã‚Šè¾¼ã¿")
min_date = df["date"].min()
max_date = df["date"].max()
selected_range = st.sidebar.date_input("è¡¨ç¤ºã™ã‚‹æœŸé–“", (min_date, max_date))

if isinstance(selected_range, tuple):
    start_date, end_date = selected_range
else:
    start_date = end_date = selected_range

filtered_df = df[(df["date"] >= start_date) & (df["date"] <= end_date)]
st.sidebar.write(f"è¡¨ç¤ºä»¶æ•°: {len(filtered_df)} ä»¶")

# è³ªå•ãƒ†ã‚­ã‚¹ãƒˆã®Embeddingå–å¾—ï¼†ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
questions = filtered_df["question"].fillna("").tolist()

if len(questions) > 0:
    with st.spinner("è³ªå•ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­..."):
        embeddings = get_embeddings(questions)

    if embeddings.shape[0] < 2:
        st.warning("è³ªå•ãŒå°‘ãªã™ãã¦ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
    else:
        # NaNãƒã‚§ãƒƒã‚¯
        if np.isnan(embeddings).any():
            st.error("Embeddingã«ç„¡åŠ¹ãªå€¤ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚")
        else:
            # ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã¯è³ªå•æ•°æœªæº€ã«èª¿æ•´
            num_clusters = min(5, embeddings.shape[0])
            kmeans = KMeans(n_clusters=num_clusters, random_state=42)
            clusters = kmeans.fit_predict(embeddings)
            filtered_df["cluster"] = clusters

            st.subheader("è³ªå•ã®è‡ªå‹•ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ")
            for cluster_num in range(num_clusters):
                st.write(f"### ã‚¯ãƒ©ã‚¹ã‚¿ {cluster_num + 1}")
                cluster_questions = filtered_df[filtered_df["cluster"] == cluster_num]["question"]
                if not cluster_questions.empty:
                    st.write(f"ä»£è¡¨è³ªå•ä¾‹: {cluster_questions.iloc[0]}")
                    st.write(f"è³ªå•æ•°: {len(cluster_questions)}")
                    with st.expander("è³ªå•ä¸€è¦§ã‚’è¡¨ç¤º"):
                        st.write(cluster_questions.tolist())


# Google Sheetsä¿å­˜ãƒœã‚¿ãƒ³
if st.button("ğŸ“¤ Google Sheetsã«ä¿å­˜ï¼ˆInsightsï¼‰"):
    try:
        save_insight_to_gsheet(filtered_df, sheet_name="Insights")
        st.success("âœ… Google Sheets ã«ä¿å­˜ã—ã¾ã—ãŸï¼")
    except Exception as e:
        st.error(f"âŒ ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ã‚°ãƒ©ãƒ•1ï¼šã‚ˆãã‚ã‚‹è³ªå•ãƒ©ãƒ³ã‚­ãƒ³ã‚°
st.subheader("ğŸ“Œ ã‚ˆãã‚ã‚‹è³ªå•ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆTop 10ï¼‰")
top_questions = filtered_df["question"].value_counts().head(10)
st.bar_chart(top_questions)

# ã‚°ãƒ©ãƒ•2ï¼šæ™‚é–“å¸¯åˆ¥ã®è³ªå•æ•°
st.subheader("ğŸ•’ æ™‚é–“å¸¯åˆ¥ã®è³ªå•æ•°ï¼ˆ0ã€œ23æ™‚ï¼‰")
hourly_counts = filtered_df.groupby("hour").size().reindex(range(24), fill_value=0)
fig1, ax1 = plt.subplots()
sns.barplot(x=hourly_counts.index, y=hourly_counts.values, ax=ax1, palette="Blues_d")
ax1.set_xlabel("æ™‚é–“å¸¯")
ax1.set_ylabel("è³ªå•æ•°")
st.pyplot(fig1)

# ã‚°ãƒ©ãƒ•3ï¼šæœˆåˆ¥ã®è³ªå•æ•°
st.subheader("ğŸ—“ æœˆåˆ¥ã®è³ªå•æ•°")
monthly_counts = filtered_df.groupby("month").size()
st.line_chart(monthly_counts)

# ã‚°ãƒ©ãƒ•4ï¼šã‚«ãƒ†ã‚´ãƒªåˆ¥ã®è³ªå•æ•°
if "category" in df.columns:
    st.subheader("ğŸ· ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®è³ªå•æ•°")
    category_counts = filtered_df["category"].value_counts()
    st.bar_chart(category_counts)

# ã‚°ãƒ©ãƒ•5ï¼šFAQå¤–ã®è³ªå•å‰²åˆ
if "faq_matched" in df.columns:
    st.subheader("â“ FAQå¤–è³ªå•ã®å‰²åˆ")
    matched_counts = filtered_df["faq_matched"].value_counts(normalize=True) * 100
    labels = ["FAQã«è©²å½“", "è©²å½“ã›ãš"]
    values = [matched_counts.get(True, 0), matched_counts.get(False, 0)]
    fig2, ax2 = plt.subplots()
    ax2.pie(values, labels=labels, autopct="%1.1f%%", startangle=90, colors=["#66b3ff", "#ff9999"])
    ax2.axis("equal")
    st.pyplot(fig2)

# æœ€è¿‘ã®è³ªå•ä¸€è¦§
with st.expander("ğŸ—‚ æœ€è¿‘ã®è³ªå•ä¸€è¦§ã‚’è¡¨ç¤º", expanded=False):
    st.dataframe(
        filtered_df[["timestamp", "question", "answer"]].sort_values("timestamp", ascending=False),
        use_container_width=True,
        hide_index=True
    )

st.caption("â€» ã“ã®åˆ†æã¯ `chat_logs.csv` ã«è¨˜éŒ²ã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚")
