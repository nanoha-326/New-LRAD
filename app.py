# LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆï¼ˆæ–‡è„ˆç†è§£å¯¾å¿œç‰ˆï¼‰
import streamlit as st
from openai import OpenAI
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os, re, unicodedata, json, base64
import gspread
from google.oauth2.service_account import Credentials

st.set_page_config(page_title="LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ", layout="centered")

# OpenAIã‚­ãƒ¼
try:
    client = OpenAI(api_key=st.secrets.OpenAIAPI.openai_api_key)
except Exception as e:
    st.error("OpenAI APIã‚­ãƒ¼ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚st.secretsã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

def append_to_gsheet(question, answer):
    try:
        sheet_key = st.secrets["GoogleSheets"]["sheet_key"]
        service_account_info = st.secrets["GoogleSheets"]["service_account_info"]
        if isinstance(service_account_info, str):
            service_account_info = json.loads(service_account_info)
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/drive"
        ]
        creds = Credentials.from_service_account_info(service_account_info, scopes=scope)
        gc = gspread.authorize(creds)
        sh = gc.open_by_key(sheet_key)
        worksheet = sh.sheet1
        worksheet.append_row([question, answer])
    except Exception as e:
        st.warning(f"Google Sheetsã¸ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def append_to_csv(question, answer, path="chat_logs.csv"):
    try:
        df = pd.DataFrame([{ "timestamp": pd.Timestamp.now().isoformat(), "question": question, "answer": answer }])
        if not os.path.exists(path):
            df.to_csv(path, index=False)
        else:
            df.to_csv(path, mode='a', header=False, index=False)
    except Exception as e:
        st.warning(f"CSVã¸ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def inject_custom_css(selected_size):
    st.markdown(
        f"""
        <style>
        .chat-text, .stCaption, .css-ffhzg2 p, .stTextInput > label {{
            font-size: {selected_size} !important;
        }}
        .stTextInput > div > div > input {{
            font-size: {selected_size} !important;
        }}
        ::placeholder {{
            font-size: {selected_size} !important;
        }}
        </style>
        """,
        unsafe_allow_html=True
    )

def get_embedding(text, model="text-embedding-3-small"):
    text = text.replace("\n", " ")
    try:
        res = client.embeddings.create(input=[text], model=model)
        return res.data[0].embedding
    except Exception as e:
        st.error(f"åŸ‹ã‚è¾¼ã¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return np.zeros(1536)

def is_valid_input(text: str) -> bool:
    text = text.strip()
    if not (3 <= len(text) <= 300):
        return False
    if len(re.findall(r'[^A-Za-z0-9ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾ \s]', text)) / len(text) > 0.3:
        return False
    try:
        unicodedata.normalize("NFKC", text).encode("utf-8")
    except UnicodeError:
        return False
    return True

def recalc_faq_embeddings(path="faq_all.csv", cached="faq_all_with_embed.csv"):
    try:
        df = pd.read_csv(path)
        with st.spinner("å…¨FAQã¸åŸ‹ã‚è¾¼ã¿è¨ˆç®—ä¸­â€¦ï¼ˆå†è¨ˆç®—ï¼‰"):
            df["embedding"] = df["è³ªå•"].apply(get_embedding)
        df["embedding"] = df["embedding"].apply(lambda x: json.dumps(x.tolist()) if hasattr(x, "tolist") else x)
        df.to_csv(cached, index=False)
        st.success("FAQåŸ‹ã‚è¾¼ã¿ã®å†è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        st.error(f"FAQåŸ‹ã‚è¾¼ã¿å†è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

@st.cache_data(show_spinner=False)
def load_faq_all(path="faq_all.csv", cached="faq_all_with_embed.csv"):
    def parse_embedding(val):
        if isinstance(val, str):
            try:
                return np.array(json.loads(val))
            except Exception:
                pass
        elif isinstance(val, list) or isinstance(val, np.ndarray):
            return np.array(val)
        return np.zeros(1536)

    if os.path.exists(cached):
        try:
            df = pd.read_csv(cached)
            df["embedding"] = df["embedding"].apply(parse_embedding)
        except Exception as e:
            st.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}ã€‚å†è¨ˆç®—ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚")
            df = pd.read_csv(path)
            with st.spinner("å…¨FAQã¸åŸ‹ã‚è¾¼ã¿è¨ˆç®—ä¸­â€¦ï¼ˆåˆå›ã®ã¿ï¼‰"):
                df["embedding"] = df["è³ªå•"].apply(get_embedding)
            df["embedding"] = df["embedding"].apply(lambda x: json.dumps(x.tolist()) if hasattr(x, "tolist") else x)
            df.to_csv(cached, index=False)
            df["embedding"] = df["embedding"].apply(parse_embedding)
    else:
        df = pd.read_csv(path)
        with st.spinner("å…¨FAQã¸åŸ‹ã‚è¾¼ã¿è¨ˆç®—ä¸­â€¦ï¼ˆåˆå›ã®ã¿ï¼‰"):
            df["embedding"] = df["è³ªå•"].apply(get_embedding)
        df["embedding"] = df["embedding"].apply(lambda x: json.dumps(x.tolist()) if hasattr(x, "tolist") else x)
        df.to_csv(cached, index=False)
        df["embedding"] = df["embedding"].apply(parse_embedding)
    return df

@st.cache_data(show_spinner=False)
def load_faq_common(path="faq_common.csv"):
    try:
        df = pd.read_csv(path, encoding="utf-8-sig")
        df.columns = df.columns.str.strip()
        return df
    except Exception as e:
        st.error(f"ã‚ˆãã‚ã‚‹è³ªå•ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame(columns=["è³ªå•", "å›ç­”"])

st.sidebar.title("âš™ï¸ è¡¨ç¤ºè¨­å®š")
font_size = st.sidebar.selectbox("æ–‡å­—ã‚µã‚¤ã‚ºã‚’é¸ã‚“ã§ãã ã•ã„", ["å°", "ä¸­", "å¤§"])
font_size_map = {"å°": "14px", "ä¸­": "18px", "å¤§": "24px"}
img_width_map = {"å°": 60, "ä¸­": 80, "å¤§": 110}
selected_font = font_size_map[font_size]
selected_img = img_width_map[font_size]

max_log = st.sidebar.slider("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ä¿å­˜ä»¶æ•°", min_value=10, max_value=200, value=100, step=10)
log_order = st.sidebar.radio("ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤ºé †", ["æ–°ã—ã„é †", "å¤ã„é †"])

if st.sidebar.button("FAQåŸ‹ã‚è¾¼ã¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥å†è¨ˆç®—"):
    recalc_faq_embeddings()
    st.cache_data.clear()
    st.experimental_rerun()

if st.sidebar.button("FAQã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"):
    st.cache_data.clear()
    st.success("FAQã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")
    st.experimental_rerun()

inject_custom_css(selected_font)

def get_base64_image(path):
    try:
        with open(path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode()
    except Exception as e:
        st.warning(f"ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return ""

image_base64 = get_base64_image("LRADimg.png")

st.markdown(
    f"""
    <div style="display:flex; align-items:center;" class="chat-header">
        <img src="data:image/png;base64,{image_base64}"
             width="{selected_img}px" style="margin-right:10px;">
        <h1 style="margin:0; font-size:40px; font-weight:bold;">LRADã‚µãƒãƒ¼ãƒˆãƒãƒ£ãƒƒãƒˆ</h1>
    </div>
    """,
    unsafe_allow_html=True
)

st.caption("â€»ã“ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯FAQã¨AIã‚’ã‚‚ã¨ã«å¿œç­”ã—ã¾ã™ãŒã€ã™ã¹ã¦ã®è³ªå•ã«æ­£ç¢ºã«å›ç­”ã§ãã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚")

faq_df = load_faq_all()
common_faq_df = load_faq_common()

def display_random_common_faqs(common_faq_df, n=3):
    if len(common_faq_df) == 0:
        st.info("ã‚ˆãã‚ã‚‹è³ªå•ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    sampled = common_faq_df.sample(min(n, len(common_faq_df)))
    for i, row in enumerate(sampled.itertuples(), 1):
        question = getattr(row, "è³ªå•", "ï¼ˆè³ªå•ãŒä¸æ˜ã§ã™ï¼‰")
        answer = getattr(row, "å›ç­”", "ï¼ˆå›ç­”ãŒä¸æ˜ã§ã™ï¼‰")
        st.markdown(
            f'<div class="chat-text"><b>â“ {question}</b><br>ğŸ…°ï¸ {answer}</div><hr>',
            unsafe_allow_html=True
        )

st.markdown("### ğŸ’¡ ã‚ˆãã‚ã‚‹è³ªå•ï¼ˆãƒ©ãƒ³ãƒ€ãƒ è¡¨ç¤ºï¼‰")
display_random_common_faqs(common_faq_df, n=3)
st.divider()

def find_top_similar(q, df, k=1):
    if len(q.strip()) < 2:
        return None, None
    q_vec = get_embedding(q)
    try:
        faq_vecs = np.stack(df["embedding"].to_numpy())
        sims = cosine_similarity([q_vec], faq_vecs)[0]
        idx = sims.argsort()[::-1][:k][0]
        return df.iloc[idx]["è³ªå•"], df.iloc[idx]["å›ç­”"]
    except Exception as e:
        st.warning(f"é¡ä¼¼è³ªå•æ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None, None

# æ–‡è„ˆç†è§£ã®ãŸã‚ã®æ–°ã—ã„å›ç­”ç”Ÿæˆé–¢æ•°
def generate_response_with_history(user_q, chat_log, ref_q, ref_a, max_turns=5):
    system_prompt = (
        "ã‚ãªãŸã¯LRADï¼ˆé èµ¤å¤–ç·šé›»å­ç†±åˆ†è§£è£…ç½®ï¼‰ã®å°‚é–€å®¶ã§ã™ã€‚"
        "ä»¥ä¸‹ã®FAQã‚’å‚è€ƒã«200æ–‡å­—ä»¥å†…ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚\n"
        f"FAQè³ªå•: {ref_q}\nFAQå›ç­”: {ref_a}"
    )
    messages = [{"role": "system", "content": system_prompt}]
    # å¤ã„é †ã«ç›´è¿‘max_turnsä»¶
    for q, a in reversed(chat_log[-max_turns:]):
        messages.append({"role": "user", "content": q})
        messages.append({"role": "assistant", "content": a})
    messages.append({"role": "user", "content": user_q})

    try:
        res = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.3,
        )
        return res.choices[0].message.content.strip()
    except Exception as e:
        st.warning(f"AIå›ç­”ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€AIã«ã‚ˆã‚‹å›ç­”ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

if "chat_log" not in st.session_state:
    st.session_state.chat_log = []

with st.form(key="chat_form", clear_on_submit=True):
    user_q = st.text_input("è³ªå•ã‚’ã©ã†ãï¼š")
    send = st.form_submit_button("é€ä¿¡")

if send and user_q:
    if not is_valid_input(user_q):
        st.warning("å…¥åŠ›ãŒä¸æ­£ã§ã™ã€‚3ã€œ300æ–‡å­—ã€è¨˜å·ç‡30%æœªæº€ã«ã—ã¦ãã ã•ã„ã€‚")
    else:
        ref_q, ref_a = find_top_similar(user_q, faq_df)
        if ref_q is None:
            answer = "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€é–¢é€£FAQãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        else:
            with st.spinner("å›ç­”ç”Ÿæˆä¸­â€¦"):
                answer = generate_response_with_history(
                    user_q,
                    st.session_state.chat_log,
                    ref_q,
                    ref_a,
                    max_turns=5
                )
        st.session_state.chat_log.insert(0, (user_q, answer))
        append_to_csv(user_q, answer)
        append_to_gsheet(user_q, answer)
        if len(st.session_state.chat_log) > max_log:
            st.session_state.chat_log = st.session_state.chat_log[:max_log]
        st.experimental_rerun()

if st.session_state.chat_log:
    st.subheader("ğŸ“œ ãƒãƒ£ãƒƒãƒˆå±¥æ­´")
    logs = st.session_state.chat_log if log_order == "æ–°ã—ã„é †" else list(reversed(st.session_state.chat_log))
    for q, a in logs:
        st.markdown(
            f'<div class="chat-text"><b>ğŸ§‘â€ğŸ’» è³ªå•:</b> {q}<br><b>ğŸ¤– å›ç­”:</b> {a}</div><hr>',
            unsafe_allow_html=True
        )
